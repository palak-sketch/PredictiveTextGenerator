{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddd387d-4fd3-457a-b1b6-d12285b17f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5a3fc8-1c4f-4779-b983-12ba18057c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e0b685-8f1e-4014-b17f-1d957935c0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version = 2.9.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version = {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc0e68a-6a69-4985-ab6a-25202775e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path = \"../Dataset/Harry Potter and the Half-Blood Prince.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a9d3b2-7ecf-42ff-8afa-dabe691acc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book contains a total of 1010864 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(datafile_path, 'rb').read().decode(encoding='utf-8')\n",
    "print(\"The book contains a total of {} characters\".format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aefb6916-b8d0-4583-8c8d-a1f34c4a24a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER ONE\n",
      "\n",
      "\n",
      "                          THE OTHER MINISTER\n",
      "\n",
      "   It was nearing midnight and the Prime Minister was sitting alone in his office, reading a long\n",
      "memo that was slipping through his brain without leaving the slightest trace of meaning behind. He\n",
      "was waiting for a call from the President of a far distant country, and between wondering when the\n",
      "wretched man would telephone, and trying to suppress unpleasant memories of what had been a\n",
      "very long, tiring, and difficult week, there was not much space in his head for anything else. The\n",
      "more he attempted to focus on the print on the page before him, the more clearly the Prime\n",
      "Minister could see the gloating face of one of his political opponents. This particular opponent had\n",
      "appeared on the news that very day, not only \n"
     ]
    }
   ],
   "source": [
    "print(text[204:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa78ca0a-b028-4b2e-b2ac-ae4f0e90f911",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare the Text\n",
    "<ul>\n",
    "    <li>Removing the staring characters stating the author and the name of the book</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286430ba-196c-4d7d-a7d2-5a5f5fe5929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[204:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af8cb12-3717-4e72-87c8-ef62724bf20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER ONE\n",
      "\n",
      "\n",
      "                          THE OTHER MINISTER\n",
      "\n",
      "   It was nearing midnight and the Prime Minister was sitting alone in his office, reading a long\n",
      "memo that was slipping through his brain without leaving the slightest trace of meaning behind. He\n",
      "was waiting for a call from the President of a far distant country, and between wondering when the\n",
      "wretched man would telephone, and trying to suppress unpleasant memories of what had been a\n",
      "very long, tiring, and difficult week, ther\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c302f70f-479e-4eb4-b53a-dbeee2357d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 number of unique charcters.\n"
     ]
    }
   ],
   "source": [
    "# Counting the unique vocabulary in the text\n",
    "vocab = sorted(set(text))\n",
    "print(\"{} number of unique charcters.\".format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54742253-ff7c-44b5-ba84-879cc84cc5f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Character to Integer Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee377a6-82c6-484e-82aa-e651e2081da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2522bd3-10ee-496f-9848-aedaa4974c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  '\\x0c':   1,\n",
      "  '\\r':   2,\n",
      "  ' ' :   3,\n",
      "  '!' :   4,\n",
      "  '(' :   5,\n",
      "  ')' :   6,\n",
      "  ',' :   7,\n",
      "  '-' :   8,\n",
      "  '.' :   9,\n",
      "  '0' :  10,\n",
      "  '1' :  11,\n",
      "  '2' :  12,\n",
      "  '3' :  13,\n",
      "  '4' :  14,\n",
      "  '5' :  15,\n",
      "  '6' :  16,\n",
      "  '7' :  17,\n",
      "  '8' :  18,\n",
      "  ':' :  19,\n",
      " ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print(' ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05115005-03f2-4f83-a14b-545405273ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ER MINISTER\\r\\n\\r\\n   It was nearing midnight and the ' \n",
      " ---- char-2-int ---- \n",
      "[26 39  3 34 30 35 30 40 41 26 39  2  0  2  0  3  3  3 30 67  3 70 48 66\n",
      "  3 61 52 48 65 56 61 54  3 60 56 51 61 56 54 55 67  3 48 61 51  3 67 55\n",
      " 52  3]\n"
     ]
    }
   ],
   "source": [
    "print('{} \\n ---- char-2-int ---- \\n{}'.format(repr(text[50:100]), text_as_int[50:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3cd8a-16c4-4d38-b726-bee1c6154a8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare the Dataset\n",
    "<p>Using the sliding window approach to select the training batch.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5358c18e-f718-4c61-a0a0-a2466391f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximum length sentence we want per character input\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07d706fd-7604-42e9-b0b5-ae1c0412fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "H\n",
      "A\n",
      "P\n",
      "T\n",
      "E\n",
      "R\n",
      " \n",
      "O\n",
      "N\n",
      "E\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Creating training examples and training batches\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(20):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5bb33b4-c298-494a-829f-c1c1fc212320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CHAPTER ONE\\r\\n\\r\\n\\r\\n                          THE OTHER MINISTER\\r\\n\\r\\n   It was nearing midnight and the P'\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "'rime Minister was sitting alone in his office, reading a long\\r\\nmemo that was slipping through his bra'\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "'in without leaving the slightest trace of meaning behind. He\\r\\nwas waiting for a call from the Preside'\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "'nt of a far distant country, and between wondering when the\\r\\nwretched man would telephone, and trying'\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "' to suppress unpleasant memories of what had been a\\r\\nvery long, tiring, and difficult week, there was'\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "' not much space in his head for anything else. The\\r\\nmore he attempted to focus on the print on the pa'\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "'ge before him, the more clearly the Prime\\r\\nMinister could see the gloating face of one of his politic'\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "'al opponents. This particular opponent had\\r\\nappeared on the news that very day, not only to enumerate'\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "' all the terrible things that had happened\\r\\nin the last week (as though anyone needed reminding) but '\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "'also to explain why each and every one of\\r\\nthem was the government’s fault.\\r\\n   The Prime Minister’s '\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(10):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n",
    "    print('-'*115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63bc94c4-d706-4dff-bd71-f8fea8a85597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e8bb38-bb62-4cd9-8568-8f88963fc751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data:  'CHAPTER ONE\\r\\n\\r\\n\\r\\n                          THE OTHER MINISTER\\r\\n\\r\\n   It was nearing midnight and the '\n",
      "Target Data:  'HAPTER ONE\\r\\n\\r\\n\\r\\n                          THE OTHER MINISTER\\r\\n\\r\\n   It was nearing midnight and the P'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input Data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target Data: ', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93a41eb2-aee6-41ee-853b-ae666164bc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input : 24  ('C')\n",
      "  expected output: 29  ('H')\n",
      "Step    1\n",
      "  input : 29  ('H')\n",
      "  expected output: 22  ('A')\n",
      "Step    2\n",
      "  input : 22  ('A')\n",
      "  expected output: 37  ('P')\n",
      "Step    3\n",
      "  input : 37  ('P')\n",
      "  expected output: 41  ('T')\n",
      "Step    4\n",
      "  input : 41  ('T')\n",
      "  expected output: 26  ('E')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input : {}  ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {}  ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2a9b8f-9a42-432d-8e7d-83e81af15628",
   "metadata": {},
   "source": [
    "# Prepare Training Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de289382-f2f9-4d2c-b1cb-9d4d0b344131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "# Buffer size to shuffle the dataset\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed2dbbe1-7d46-463c-8656-766fedd418d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape=<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(\"Dataset Shape={}\".format(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62b424-191f-4e22-aa47-61f764ff73c4",
   "metadata": {},
   "source": [
    "# Prepare Model\n",
    "\n",
    "We prepare the utility function to generate the architecture of our deep learning based language model. We leverage the high level tf.keras API for creating this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6e6deb4-5ea5-47d9-8074-9827ea72bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \"\"\"\n",
    "    This function creates a model object.\n",
    "    Parameters:\n",
    "        vocab_size: number of unique characters\n",
    "        embedding_dim: size of embedding vector. Typically in powers of 2\n",
    "        rnn_units: number of GRU units to be used\n",
    "        batch_size: batch size for training the model\n",
    "    Returns:\n",
    "        tf.keras model object\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a5f7100-2cfe-44fa-a775-3e2d843cef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "#embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "#number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c07ff191-07e8-4a9c-9b69-969fc221908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size=len(vocab),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74ddee54-95cf-4070-86ff-76c1ec0c8f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           20992     \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 82)            84050     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,043,346\n",
      "Trainable params: 4,043,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1df193d8-b951-46d8-80c8-b61159153189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "222aa029-d84f-4048-9def-66d7d0d94c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedffd52-76db-4558-8a6d-f6d3070c1e1d",
   "metadata": {},
   "source": [
    "# Setup Callbacks\n",
    "     We setup a single callback to store training checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca77d99d-1db9-429b-9973-89de271c573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = r'data/training_checkpoints'\n",
    "#Name the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8fed6c0-3222-4461-a636-2c2f7c663c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bdb305-ea92-47a8-88ee-acac04897ccf",
   "metadata": {},
   "source": [
    "# Train the Language Model\n",
    "\n",
    "    Now we shall train the model based on the training dataset perpared.\n",
    "    We train for a few epoch first to check if the model is learning or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e39b4f83-98cc-4ee6-baa9-bd56c556ed6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "156/156 [==============================] - 151s 955ms/step - loss: 2.7408\n",
      "Epoch 2/40\n",
      "156/156 [==============================] - 155s 990ms/step - loss: 1.9378\n",
      "Epoch 3/40\n",
      "156/156 [==============================] - 147s 940ms/step - loss: 1.6412\n",
      "Epoch 4/40\n",
      "156/156 [==============================] - 167s 1s/step - loss: 1.4605\n",
      "Epoch 5/40\n",
      "156/156 [==============================] - 159s 1s/step - loss: 1.3524\n",
      "Epoch 6/40\n",
      "156/156 [==============================] - 186s 1s/step - loss: 1.2800\n",
      "Epoch 7/40\n",
      "156/156 [==============================] - 170s 1s/step - loss: 1.2259\n",
      "Epoch 8/40\n",
      "156/156 [==============================] - 192s 1s/step - loss: 1.1814\n",
      "Epoch 9/40\n",
      "156/156 [==============================] - 187s 1s/step - loss: 1.1428\n",
      "Epoch 10/40\n",
      "156/156 [==============================] - 151s 962ms/step - loss: 1.1071\n",
      "Epoch 11/40\n",
      "156/156 [==============================] - 153s 974ms/step - loss: 1.0725\n",
      "Epoch 12/40\n",
      "156/156 [==============================] - 153s 978ms/step - loss: 1.0387\n",
      "Epoch 13/40\n",
      "156/156 [==============================] - 156s 997ms/step - loss: 1.0064\n",
      "Epoch 14/40\n",
      "156/156 [==============================] - 156s 994ms/step - loss: 0.9724\n",
      "Epoch 15/40\n",
      "156/156 [==============================] - 161s 1s/step - loss: 0.9402\n",
      "Epoch 16/40\n",
      "156/156 [==============================] - 156s 998ms/step - loss: 0.9060\n",
      "Epoch 17/40\n",
      "156/156 [==============================] - 160s 1s/step - loss: 0.8738\n",
      "Epoch 18/40\n",
      "156/156 [==============================] - 158s 1s/step - loss: 0.8419\n",
      "Epoch 19/40\n",
      "156/156 [==============================] - 159s 1s/step - loss: 0.8098\n",
      "Epoch 20/40\n",
      "156/156 [==============================] - 159s 1s/step - loss: 0.7805\n",
      "Epoch 21/40\n",
      "156/156 [==============================] - 156s 993ms/step - loss: 0.7523\n",
      "Epoch 22/40\n",
      "156/156 [==============================] - 158s 1s/step - loss: 0.7275\n",
      "Epoch 23/40\n",
      "156/156 [==============================] - 155s 986ms/step - loss: 0.7043\n",
      "Epoch 24/40\n",
      "156/156 [==============================] - 154s 985ms/step - loss: 0.6837\n",
      "Epoch 25/40\n",
      "156/156 [==============================] - 157s 1000ms/step - loss: 0.6647\n",
      "Epoch 26/40\n",
      "156/156 [==============================] - 155s 986ms/step - loss: 0.6471\n",
      "Epoch 27/40\n",
      "156/156 [==============================] - 154s 983ms/step - loss: 0.6347\n",
      "Epoch 28/40\n",
      "156/156 [==============================] - 154s 983ms/step - loss: 0.6223\n",
      "Epoch 29/40\n",
      "156/156 [==============================] - 155s 990ms/step - loss: 0.6094\n",
      "Epoch 30/40\n",
      "156/156 [==============================] - 158s 1s/step - loss: 0.6014\n",
      "Epoch 31/40\n",
      "156/156 [==============================] - 155s 991ms/step - loss: 0.5917\n",
      "Epoch 32/40\n",
      "156/156 [==============================] - 156s 994ms/step - loss: 0.5852\n",
      "Epoch 33/40\n",
      "156/156 [==============================] - 157s 1s/step - loss: 0.5803\n",
      "Epoch 34/40\n",
      "156/156 [==============================] - 155s 987ms/step - loss: 0.5746\n",
      "Epoch 35/40\n",
      "156/156 [==============================] - 159s 1s/step - loss: 0.5710\n",
      "Epoch 36/40\n",
      "156/156 [==============================] - 154s 984ms/step - loss: 0.5667\n",
      "Epoch 37/40\n",
      "156/156 [==============================] - 160s 1s/step - loss: 0.5605\n",
      "Epoch 38/40\n",
      "156/156 [==============================] - 156s 996ms/step - loss: 0.5580\n",
      "Epoch 39/40\n",
      "156/156 [==============================] - 154s 985ms/step - loss: 0.5572\n",
      "Epoch 40/40\n",
      "156/156 [==============================] - 162s 1s/step - loss: 0.5567\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "\n",
    "history=model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a85ceec-cad9-4689-9a76-a8d2e953330c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bfe098e4f6de4d84\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bfe098e4f6de4d84\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef12dc93-0bbf-44da-ab10-1ab99658a361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir logs (started 0:00:00 ago; pid 22692)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() #to view TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6863711-2657-4b0e-9671-1e7e7d52b37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir logs (started 0:00:00 ago; port 6006, pid 22692).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-53c9704464a71b6b\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-53c9704464a71b6b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2033b8-cf69-42d4-9bc5-137aa965d604",
   "metadata": {},
   "source": [
    "# Generate Text\n",
    "    based on the training done, we need to generate some text and the see what the model has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eee343d3-f048-4f58-a72b-1e21d49e3755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/training_checkpoints\\\\ckpt_40'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f920dd-858a-4238-a6fd-3b41b9413c25",
   "metadata": {},
   "source": [
    "# Model Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b86ea906-7598-4c50-9e6c-8617519a139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5e456e5-1a3d-407d-a1e6-afab87e7d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, context_string, num_generate=1000, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        model: tf.keras object trained on a sufficient sized corpus\n",
    "        num_generate: number of characters to be generated\n",
    "        temperature: parameter to control randomness of outputs\n",
    "    Returns:\n",
    "        string: context_string + text_generated\n",
    "    \"\"\"\n",
    "    #vectorizing: convert context string into string indices\n",
    "    input_eval = [char2idx[s] for s in context_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    #String for generated characters\n",
    "    text_generated = []\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    #Loop till required number of characters are generated\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        #temperature helps in controlling the character returned by the model.\n",
    "        predictions = predictions/temperature\n",
    "        #Sampling over a categorical distribution\n",
    "        prediction_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        \n",
    "        #predicted character acts as input for next step\n",
    "        input_eval = tf.expand_dims([prediction_id], 0)\n",
    "        \n",
    "        text_generated.append(idx2char[prediction_id])\n",
    "    return (context_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00fe95ed-1971-4df0-9da1-c7348cf8abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This particular opponent that she could show any time down asl,” said Harry, “the restrid tell him, I return from whired awa\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"This particular opponent\", num_generate=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe210028-316e-4bf0-bbed-c3a29558f808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81fe72-7dd8-4507-a67c-f8a8481a0576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
